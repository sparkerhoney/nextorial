{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5228,"status":"ok","timestamp":1698590007519,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"aBN38mPBuvUv","outputId":"d82e4f92-a22e-44f0-a1b0-3bfe8b36cd0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n","Requirement already satisfied: scikit_learn\u003e0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n","Requirement already satisfied: scipy\u003e1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.3)\n","Requirement already satisfied: torch\u003e=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.1.0+cu118)\n","Requirement already satisfied: tqdm\u003e=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn\u003e0.21-\u003epytorch-tabnet) (1.3.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn\u003e0.21-\u003epytorch-tabnet) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (2.1.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.3-\u003epytorch-tabnet) (2.1.3)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.3-\u003epytorch-tabnet) (1.3.0)\n","Installing collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-4.1.0\n"]}],"source":["! pip install pytorch-tabnet"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5644,"status":"ok","timestamp":1698596284780,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"IpKn2mzLOkJc","outputId":"8a3f3763-55d4-4736-81cd-2748f39c32b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting optuna\n","  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic\u003e=1.5.0 (from optuna)\n","  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog (from optuna)\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n","Requirement already satisfied: sqlalchemy\u003e=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.22)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic\u003e=1.5.0-\u003eoptuna)\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions\u003e=4 in /usr/local/lib/python3.10/dist-packages (from alembic\u003e=1.5.0-\u003eoptuna) (4.5.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy\u003e=1.3.0-\u003eoptuna) (3.0.0)\n","Requirement already satisfied: MarkupSafe\u003e=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako-\u003ealembic\u003e=1.5.0-\u003eoptuna) (2.1.3)\n","Installing collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.12.1 colorlog-6.7.0 optuna-3.4.0\n"]}],"source":["! pip install optuna"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1373,"status":"ok","timestamp":1698590008887,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"SWrLKXATvQ3L"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":1373,"status":"ok","timestamp":1698596151576,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"DJVHmzp3wXUl"},"outputs":[],"source":["match_data = pd.read_csv('/content/drive/MyDrive/nextorial/data/match_data.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/nextorial/data/test_data.csv')"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698596153027,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"d9IDB-y-vpZc"},"outputs":[],"source":["class DataProcessor:\n","\n","    def __init__(self, df):\n","        self.data = df\n","\n","    @staticmethod\n","    # def convert_tier_to_numeric(tier):\n","    #     tier_dict = {\n","    #         'unranked': 0,\n","    #         'bronze': 1,\n","    #         'silver': 2,\n","    #         'gold': 3,\n","    #         'platinum': 4,\n","    #         'diamond': 5,\n","    #         'master': 6\n","    #     }\n","    #     return tier_dict.get(tier, -1)\n","\n","    @staticmethod\n","    def convert_tier_to_exponential_weight(tier):\n","        tier_dict = {\n","            'unranked': 0,\n","            'bronze': 1,\n","            'silver': 2,\n","            'gold': 3,\n","            'platinum': 4,\n","            'diamond': 5,\n","            'master': 6\n","        }\n","        tier_numeric = tier_dict.get(tier, -1)\n","        return np.exp(tier_numeric)\n","\n","    def add_tier_exponential_weight(self):\n","        self.data['tier_exp_weight'] = self.data['tier'].apply(self.convert_tier_to_exponential_weight)\n","        return self.data\n","\n","    # def calculate_team_features(self):\n","    #     return self.data.groupby(['matchid', 'teamid']).agg({\n","    #         'mmr': 'mean',\n","    #         'winstreak': 'mean',\n","    #         'losestreak': 'mean',\n","    #         'recentwinprob': 'mean'\n","    #     }).reset_index()\n","\n","    def preprocess(self):\n","        # match_team_features = self.calculate_team_features()\n","        # self.data = self.data.merge(match_team_features, on=['matchid', 'teamid'], suffixes=('', '_team_avg'))\n","        self.data = self.normalize_column('accumatches')\n","        self.data = self.compute_team_stats()\n","        self.data = self.compute_recent_performance_index()\n","        self.data = self.process_guild_info(202068.571428571428400)\n","        self.data = self.compute_mmr_diff_and_variance()\n","        self.data = self.compute_recent_winprob_stats()\n","        self.data = self.apply_tier_conversion_and_compute_average()\n","        self.data = self.compute_streak_rate()\n","        self.data = self.guild_mean()\n","        self.data = self.guild_median()\n","        self.data = self.guild_mode()\n","        self.data = self.add_tier_exponential_weight()\n","\n","    # guild_membership\n","    def guild_mean(self):\n","        df = self.data.copy()\n","        df['guildid'].fillna('NoGuild', inplace=True)\n","        df['tier_numeric'] = df['tier'].map(self.convert_tier_to_exponential_weight)\n","        guild_mean = df.groupby('guildid')[['mmr', 'winstreak', 'recentwinprob', 'accumatches', 'tier_numeric']].mean()\n","        new_columns = {col: f'{col}guild_mean' for col in guild_mean.columns}\n","        guild_mean.rename(columns=new_columns, inplace=True)\n","        df = pd.merge(df, guild_mean, on='guildid', how='left')\n","        return df\n","\n","    def guild_median(self):\n","        df = self.data.copy()\n","        df['guildid'].fillna('NoGuild', inplace=True)\n","        df['tier_numeric'] = df['tier'].map(self.convert_tier_to_exponential_weight)\n","        guild_median = df.groupby('guildid')[['mmr', 'winstreak', 'recentwinprob', 'accumatches', 'tier_numeric']].median()\n","        new_columns = {col: f'{col}guild_median' for col in guild_median.columns}\n","        guild_median.rename(columns=new_columns, inplace=True)\n","        df = pd.merge(df, guild_median, on='guildid', how='left')\n","        return df\n","\n","    def guild_mode(self):\n","        df = self.data.copy()\n","        df['guildid'].fillna('NoGuild', inplace=True)\n","        df['tier_numeric'] = df['tier'].map(self.convert_tier_to_exponential_weight)\n","\n","        def calculate_mode(group):\n","            return group.mode().iloc[0]\n","\n","        guild_mode = df.groupby('guildid')[['mmr', 'winstreak', 'recentwinprob', 'accumatches', 'tier_numeric']].apply(calculate_mode)\n","        new_columns = {col: f'{col}guild_mode' for col in guild_mode.columns}\n","        guild_mode.rename(columns=new_columns, inplace=True)\n","        df = pd.merge(df, guild_mode, on='guildid', how='left')\n","        return df\n","\n","    def normalize_column(self, column):\n","        self.data[f'normalized_{column}'] = (self.data[column] - self.data[column].min()) / (self.data[column].max() - self.data[column].min())\n","        return self.data\n","\n","    def compute_team_stats(self):\n","        grouped = self.data.groupby(['matchid', 'teamid'])\n","        self.data['team_max_accumatches'] = grouped['accumatches'].transform('max')\n","        self.data['team_min_accumatches'] = grouped['accumatches'].transform('min')\n","        self.data['accumatches_diff'] = self.data['team_max_accumatches'] - self.data['team_min_accumatches']\n","        self.data['accumatches_variance'] = grouped['accumatches'].transform('var')\n","        return self.data\n","\n","    def compute_recent_performance_index(self):\n","        self.data['recent_performance_index'] = self.data['winstreak'] * self.data['recentwinprob']\n","        return self.data\n","\n","    def process_guild_info(self, threshold):\n","        guild_mean_mmr = self.data.groupby('guildid')['mmr'].mean()\n","        self.data['guild_mean_mmr'] = self.data['guildid'].map(guild_mean_mmr)\n","        self.data['high_mmr_guild'] = (self.data['guild_mean_mmr'] \u003e threshold).astype(int)\n","        return self.data\n","\n","    def compute_mmr_diff_and_variance(self):\n","        mmr_diff_grouped = self.data.groupby('teamid')['mmr'].agg(['max', 'min'])\n","        self.data['mmr_diff'] = self.data['teamid'].map(mmr_diff_grouped['max'] - mmr_diff_grouped['min'])\n","        mmr_variance_grouped = self.data.groupby('teamid')['mmr'].var()\n","        self.data['mmr_variance'] = self.data['teamid'].map(mmr_variance_grouped)\n","        return self.data\n","\n","    def compute_recent_winprob_stats(self):\n","        grouped = self.data.groupby('matchid')\n","        self.data['recentwinprob_max'] = grouped['recentwinprob'].transform('max')\n","        self.data['recentwinprob_min'] = grouped['recentwinprob'].transform('min')\n","        self.data['recentwinprob_diff'] = self.data['recentwinprob_max'] - self.data['recentwinprob_min']\n","        self.data['recentwinprob_mean'] = grouped['recentwinprob'].transform('mean')\n","        self.data['recentwinprob_diff_from_mean'] = (self.data['recentwinprob'] - self.data['recentwinprob_mean'])**2\n","        self.data['recentwinprob_variance'] = grouped['recentwinprob_diff_from_mean'].transform('mean')\n","        return self.data\n","\n","    def apply_tier_conversion_and_compute_average(self):\n","        self.data['tier_numeric'] = self.data['tier'].apply(self.convert_tier_to_exponential_weight)\n","        average_tier = self.data.groupby(['matchid', 'teamid'])['tier_numeric'].mean().reset_index()\n","        average_tier.rename(columns={'tier_numeric': 'average_tier'}, inplace=True)\n","        self.data = self.data.merge(average_tier, on=['matchid', 'teamid'])\n","        return self.data\n","\n","    @staticmethod\n","    def calculate_streak_rate(row):\n","        winstreak, losestreak = row['winstreak'], row['losestreak']\n","        if winstreak + losestreak == 0:\n","            return 0\n","        return winstreak / (winstreak + losestreak)\n","\n","    def compute_streak_rate(self):\n","        self.data['streak_rate'] = self.data.apply(self.calculate_streak_rate, axis=1)\n","        return self.data"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":17848,"status":"ok","timestamp":1698596180332,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"Rtq23JFVwEt4"},"outputs":[],"source":["processor = DataProcessor(match_data)\n","processor.preprocess()\n","processed_data = processor.data"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":11096,"status":"ok","timestamp":1698592355864,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"wvSF3Jvv6Rbq"},"outputs":[],"source":["# # Processed data is already defined in the context, we'll just export it to a CSV file\n","# processed_data.to_csv('/content/drive/MyDrive/nextorial/data/processed_match_data.csv', index=False)"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":3658,"status":"ok","timestamp":1698596203057,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"Y_yZXSVm4_Gq"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split\n","\n","# 데이터에서 특성과 타겟 변수를 분리합니다.\n","target = 'matchresult'\n","# Drop identifiers and the original 'tier' feature\n","features_to_drop = ['createdatekst', 'matchid', 'accountid', 'guildid', 'tier', 'matchscore', 'isDrop', 'isEscape']\n","features = processed_data.columns.drop([target] + features_to_drop)\n","X = processed_data[features]\n","y = processed_data[target]\n","\n","# 수치형 및 범주형 데이터를 위한 변환기 정의\n","numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n","categorical_features = X.select_dtypes(include=['object']).columns\n","\n","# 순서형 특성은 이미 'tier_numeric'으로 변환되어 있으므로 여기서는 처리하지 않습니다.\n","\n","# 수치형 및 범주형 데이터에 대한 파이프라인을 만듭니다.\n","numeric_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median'))  # NaN 값을 중앙값으로 대체\n","])\n","\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),  # NaN 값을 최빈값으로 대체\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # 원-핫 인코딩\n","])\n","\n","# ColumnTransformer를 생성하여 변환기를 결합합니다.\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ],\n","    remainder='passthrough'  # 나머지 열은 변경하지 않고 유지\n",")\n","\n","# 전처리를 특성 데이터에 적용합니다.\n","X_encoded = preprocessor.fit_transform(X)\n","\n","# 데이터셋을 훈련 세트와 검증/테스트 세트로 분할합니다.\n","X_temp, X_test, y_temp, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3852,"status":"ok","timestamp":1698592381280,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"zkjaWTV75tHN"},"outputs":[],"source":["import torch, gc\n","\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1908686,"status":"ok","timestamp":1698594373989,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"_5GHgZ9eQ7NR","outputId":"bc0b8bcb-9463-424e-eee1-ff1222cdbd6e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.68641 | val_0_auc: 0.58574 |  0:08:25s\n","epoch 1  | loss: 0.68401 | val_0_auc: 0.58654 |  0:17:22s\n","Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_val_0_auc = 0.58654\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}],"source":["# from pytorch_tabnet.tab_model import TabNetClassifier\n","\n","# clf = TabNetClassifier()\n","# clf.fit(\n","#     X_train, y_train,\n","#     eval_set=[(X_valid, y_valid)],\n","#     batch_size = 8,\n","#     max_epochs = 2,\n","# )\n","# preds = clf.predict(X_test)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":622036,"status":"ok","timestamp":1698595972909,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"esRGsRfDJwZD","outputId":"f5d5cded-00e2-41c0-95e4-477b493834c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.68944 | val_0_auc: 0.57001 |  0:00:12s\n","epoch 1  | loss: 0.67928 | val_0_auc: 0.59253 |  0:00:24s\n","epoch 2  | loss: 0.678   | val_0_auc: 0.59655 |  0:00:36s\n","epoch 3  | loss: 0.67802 | val_0_auc: 0.59728 |  0:00:48s\n","epoch 4  | loss: 0.67714 | val_0_auc: 0.59968 |  0:01:00s\n","epoch 5  | loss: 0.67629 | val_0_auc: 0.60159 |  0:01:12s\n","epoch 6  | loss: 0.67559 | val_0_auc: 0.60327 |  0:01:24s\n","epoch 7  | loss: 0.67462 | val_0_auc: 0.60496 |  0:01:36s\n","epoch 8  | loss: 0.67441 | val_0_auc: 0.60629 |  0:01:48s\n","epoch 9  | loss: 0.67373 | val_0_auc: 0.60862 |  0:02:00s\n","epoch 10 | loss: 0.67488 | val_0_auc: 0.5941  |  0:02:13s\n","epoch 11 | loss: 0.6761  | val_0_auc: 0.60057 |  0:02:25s\n","epoch 12 | loss: 0.67553 | val_0_auc: 0.6047  |  0:02:37s\n","epoch 13 | loss: 0.67401 | val_0_auc: 0.60788 |  0:02:49s\n","epoch 14 | loss: 0.67305 | val_0_auc: 0.60875 |  0:03:01s\n","epoch 15 | loss: 0.67302 | val_0_auc: 0.60912 |  0:03:13s\n","epoch 16 | loss: 0.67268 | val_0_auc: 0.61012 |  0:03:26s\n","epoch 17 | loss: 0.67241 | val_0_auc: 0.61135 |  0:03:38s\n","epoch 18 | loss: 0.67196 | val_0_auc: 0.61219 |  0:03:50s\n","epoch 19 | loss: 0.67174 | val_0_auc: 0.61208 |  0:04:02s\n","epoch 20 | loss: 0.67182 | val_0_auc: 0.612   |  0:04:14s\n","epoch 21 | loss: 0.67192 | val_0_auc: 0.61251 |  0:04:26s\n","epoch 22 | loss: 0.67146 | val_0_auc: 0.61165 |  0:04:38s\n","epoch 23 | loss: 0.67111 | val_0_auc: 0.61255 |  0:04:50s\n","epoch 24 | loss: 0.671   | val_0_auc: 0.61186 |  0:05:02s\n","epoch 25 | loss: 0.67106 | val_0_auc: 0.61343 |  0:05:14s\n","epoch 26 | loss: 0.67074 | val_0_auc: 0.61477 |  0:05:26s\n","epoch 27 | loss: 0.67046 | val_0_auc: 0.61426 |  0:05:38s\n","epoch 28 | loss: 0.67062 | val_0_auc: 0.61396 |  0:05:50s\n","epoch 29 | loss: 0.6705  | val_0_auc: 0.61483 |  0:06:02s\n","epoch 30 | loss: 0.67013 | val_0_auc: 0.61609 |  0:06:14s\n","epoch 31 | loss: 0.66972 | val_0_auc: 0.61626 |  0:06:26s\n","epoch 32 | loss: 0.6699  | val_0_auc: 0.61667 |  0:06:38s\n","epoch 33 | loss: 0.67021 | val_0_auc: 0.61511 |  0:06:50s\n","epoch 34 | loss: 0.66971 | val_0_auc: 0.61666 |  0:07:02s\n","epoch 35 | loss: 0.66969 | val_0_auc: 0.61434 |  0:07:14s\n","epoch 36 | loss: 0.66943 | val_0_auc: 0.61845 |  0:07:26s\n","epoch 37 | loss: 0.66887 | val_0_auc: 0.61857 |  0:07:38s\n","epoch 38 | loss: 0.66933 | val_0_auc: 0.61479 |  0:07:50s\n","epoch 39 | loss: 0.66891 | val_0_auc: 0.61763 |  0:08:02s\n","epoch 40 | loss: 0.66898 | val_0_auc: 0.61706 |  0:08:14s\n","epoch 41 | loss: 0.66907 | val_0_auc: 0.61321 |  0:08:26s\n","epoch 42 | loss: 0.66989 | val_0_auc: 0.61628 |  0:08:38s\n","epoch 43 | loss: 0.66927 | val_0_auc: 0.61873 |  0:08:50s\n","epoch 44 | loss: 0.66954 | val_0_auc: 0.61616 |  0:09:02s\n","epoch 45 | loss: 0.66905 | val_0_auc: 0.6174  |  0:09:14s\n","epoch 46 | loss: 0.6687  | val_0_auc: 0.61875 |  0:09:26s\n","epoch 47 | loss: 0.66814 | val_0_auc: 0.61945 |  0:09:38s\n","epoch 48 | loss: 0.66805 | val_0_auc: 0.61865 |  0:09:50s\n","epoch 49 | loss: 0.66847 | val_0_auc: 0.62004 |  0:10:02s\n","Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_val_0_auc = 0.62004\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}],"source":["# from pytorch_tabnet.tab_model import TabNetClassifier\n","\n","# clf = TabNetClassifier()\n","# clf.fit(\n","#     X_train, y_train,\n","#     eval_set=[(X_valid, y_valid)],\n","#     batch_size = 1024,\n","#     max_epochs = 50,\n","# )\n","# preds = clf.predict(X_test)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2092535,"status":"error","timestamp":1698598388239,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"Ao3oWNvbKkRE"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-10-29 18:09:13,652] A new study created in memory with name: TabNet optimization\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69429 | valid_accuracy: 0.50973 |  0:00:12s\n","epoch 1  | loss: 0.69235 | valid_accuracy: 0.5007  |  0:00:23s\n","epoch 2  | loss: 0.69188 | valid_accuracy: 0.50082 |  0:00:35s\n","epoch 3  | loss: 0.6913  | valid_accuracy: 0.50074 |  0:00:47s\n","epoch 4  | loss: 0.69128 | valid_accuracy: 0.50071 |  0:00:59s\n","epoch 5  | loss: 0.69128 | valid_accuracy: 0.50071 |  0:01:11s\n","\n","Early stopping occurred at epoch 5 with best_epoch = 0 and best_valid_accuracy = 0.50973\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:10:50,066] Trial 0 finished with value: 0.5097286694201786 and parameters: {'max_epochs': 11, 'batch_size': 512, 'learning_rate': 0.0750569251240507}. Best is trial 0 with value: 0.5097286694201786.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69854 | valid_accuracy: 0.504   |  0:00:06s\n","epoch 1  | loss: 0.6907  | valid_accuracy: 0.5201  |  0:00:13s\n","epoch 2  | loss: 0.68954 | valid_accuracy: 0.53061 |  0:00:20s\n","epoch 3  | loss: 0.68866 | valid_accuracy: 0.53362 |  0:00:27s\n","epoch 4  | loss: 0.68848 | valid_accuracy: 0.53405 |  0:00:34s\n","epoch 5  | loss: 0.68821 | valid_accuracy: 0.53061 |  0:00:41s\n","epoch 6  | loss: 0.68813 | valid_accuracy: 0.53153 |  0:00:48s\n","epoch 7  | loss: 0.68795 | valid_accuracy: 0.53183 |  0:00:55s\n","epoch 8  | loss: 0.68749 | valid_accuracy: 0.53319 |  0:01:02s\n","epoch 9  | loss: 0.68727 | valid_accuracy: 0.53207 |  0:01:09s\n","\n","Early stopping occurred at epoch 9 with best_epoch = 4 and best_valid_accuracy = 0.53405\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:12:12,766] Trial 1 finished with value: 0.5340472970503308 and parameters: {'max_epochs': 26, 'batch_size': 1024, 'learning_rate': 0.018006814304556498}. Best is trial 1 with value: 0.5340472970503308.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69522 | valid_accuracy: 0.5128  |  0:00:11s\n","epoch 1  | loss: 0.69078 | valid_accuracy: 0.52428 |  0:00:24s\n","epoch 2  | loss: 0.68959 | valid_accuracy: 0.53022 |  0:00:36s\n","epoch 3  | loss: 0.68886 | valid_accuracy: 0.53386 |  0:00:47s\n","epoch 4  | loss: 0.68814 | valid_accuracy: 0.53269 |  0:00:59s\n","epoch 5  | loss: 0.6884  | valid_accuracy: 0.52491 |  0:01:12s\n","epoch 6  | loss: 0.68832 | valid_accuracy: 0.53144 |  0:01:24s\n","epoch 7  | loss: 0.68791 | valid_accuracy: 0.53548 |  0:01:36s\n","epoch 8  | loss: 0.68663 | valid_accuracy: 0.53642 |  0:01:48s\n","epoch 9  | loss: 0.6861  | valid_accuracy: 0.54149 |  0:02:00s\n","epoch 10 | loss: 0.68585 | valid_accuracy: 0.54108 |  0:02:12s\n","epoch 11 | loss: 0.68552 | valid_accuracy: 0.54231 |  0:02:24s\n","epoch 12 | loss: 0.68503 | valid_accuracy: 0.5407  |  0:02:36s\n","epoch 13 | loss: 0.68452 | valid_accuracy: 0.52378 |  0:02:48s\n","epoch 14 | loss: 0.68416 | valid_accuracy: 0.53414 |  0:03:00s\n","epoch 15 | loss: 0.68418 | valid_accuracy: 0.54039 |  0:03:12s\n","epoch 16 | loss: 0.68362 | valid_accuracy: 0.54367 |  0:03:24s\n","epoch 17 | loss: 0.68354 | valid_accuracy: 0.54096 |  0:03:36s\n","epoch 18 | loss: 0.68325 | valid_accuracy: 0.54407 |  0:03:48s\n","epoch 19 | loss: 0.68293 | valid_accuracy: 0.54142 |  0:04:00s\n","epoch 20 | loss: 0.68271 | valid_accuracy: 0.54202 |  0:04:12s\n","epoch 21 | loss: 0.68249 | valid_accuracy: 0.52951 |  0:04:24s\n","epoch 22 | loss: 0.68226 | valid_accuracy: 0.54322 |  0:04:36s\n","epoch 23 | loss: 0.68207 | valid_accuracy: 0.54388 |  0:04:48s\n","\n","Early stopping occurred at epoch 23 with best_epoch = 18 and best_valid_accuracy = 0.54407\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:17:25,477] Trial 2 finished with value: 0.5440744666593564 and parameters: {'max_epochs': 27, 'batch_size': 512, 'learning_rate': 0.025743661804211764}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69771 | valid_accuracy: 0.52068 |  0:00:11s\n","epoch 1  | loss: 0.69085 | valid_accuracy: 0.52373 |  0:00:23s\n","epoch 2  | loss: 0.68979 | valid_accuracy: 0.52844 |  0:00:35s\n","epoch 3  | loss: 0.68895 | valid_accuracy: 0.52668 |  0:00:47s\n","epoch 4  | loss: 0.68858 | valid_accuracy: 0.52662 |  0:00:59s\n","epoch 5  | loss: 0.68874 | valid_accuracy: 0.52475 |  0:01:11s\n","epoch 6  | loss: 0.6883  | valid_accuracy: 0.52547 |  0:01:23s\n","epoch 7  | loss: 0.68867 | valid_accuracy: 0.52359 |  0:01:35s\n","\n","Early stopping occurred at epoch 7 with best_epoch = 2 and best_valid_accuracy = 0.52844\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:19:25,382] Trial 3 finished with value: 0.5284428037087125 and parameters: {'max_epochs': 29, 'batch_size': 512, 'learning_rate': 0.013097618482247813}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.70264 | valid_accuracy: 0.51736 |  0:00:22s\n","epoch 1  | loss: 0.69177 | valid_accuracy: 0.52291 |  0:00:45s\n","epoch 2  | loss: 0.69062 | valid_accuracy: 0.52395 |  0:01:07s\n","epoch 3  | loss: 0.69012 | valid_accuracy: 0.52289 |  0:01:30s\n","epoch 4  | loss: 0.6898  | valid_accuracy: 0.52721 |  0:01:52s\n","epoch 5  | loss: 0.68939 | valid_accuracy: 0.52931 |  0:02:15s\n","epoch 6  | loss: 0.68895 | valid_accuracy: 0.52994 |  0:02:37s\n","epoch 7  | loss: 0.68867 | valid_accuracy: 0.52977 |  0:03:00s\n","epoch 8  | loss: 0.68822 | valid_accuracy: 0.53165 |  0:03:22s\n","epoch 9  | loss: 0.68776 | valid_accuracy: 0.53154 |  0:03:45s\n","epoch 10 | loss: 0.68782 | valid_accuracy: 0.53457 |  0:04:07s\n","epoch 11 | loss: 0.68724 | valid_accuracy: 0.53354 |  0:04:30s\n","epoch 12 | loss: 0.68784 | valid_accuracy: 0.53042 |  0:04:52s\n","epoch 13 | loss: 0.68754 | valid_accuracy: 0.53308 |  0:05:14s\n","epoch 14 | loss: 0.68701 | valid_accuracy: 0.53177 |  0:05:37s\n","Stop training because you reached max_epochs = 15 with best_epoch = 10 and best_valid_accuracy = 0.53457\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:25:50,103] Trial 4 finished with value: 0.5345711953409603 and parameters: {'max_epochs': 15, 'batch_size': 256, 'learning_rate': 0.003888339462482565}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69298 | valid_accuracy: 0.50706 |  0:00:22s\n","epoch 1  | loss: 0.69103 | valid_accuracy: 0.51952 |  0:00:44s\n","epoch 2  | loss: 0.69148 | valid_accuracy: 0.50071 |  0:01:07s\n","epoch 3  | loss: 0.69138 | valid_accuracy: 0.50071 |  0:01:29s\n","epoch 4  | loss: 0.69135 | valid_accuracy: 0.50071 |  0:01:52s\n","epoch 5  | loss: 0.69144 | valid_accuracy: 0.50071 |  0:02:14s\n","epoch 6  | loss: 0.6914  | valid_accuracy: 0.50071 |  0:02:37s\n","\n","Early stopping occurred at epoch 6 with best_epoch = 1 and best_valid_accuracy = 0.51952\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:29:14,571] Trial 5 finished with value: 0.5195243490868331 and parameters: {'max_epochs': 10, 'batch_size': 256, 'learning_rate': 0.0628342950523843}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69511 | valid_accuracy: 0.51175 |  0:00:06s\n","epoch 1  | loss: 0.69024 | valid_accuracy: 0.52453 |  0:00:13s\n","epoch 2  | loss: 0.68933 | valid_accuracy: 0.52353 |  0:00:20s\n","epoch 3  | loss: 0.68924 | valid_accuracy: 0.52875 |  0:00:27s\n","epoch 4  | loss: 0.68807 | valid_accuracy: 0.53434 |  0:00:34s\n","epoch 5  | loss: 0.6873  | valid_accuracy: 0.53383 |  0:00:41s\n","epoch 6  | loss: 0.68736 | valid_accuracy: 0.52809 |  0:00:48s\n","epoch 7  | loss: 0.6874  | valid_accuracy: 0.53419 |  0:00:55s\n","epoch 8  | loss: 0.68669 | valid_accuracy: 0.53535 |  0:01:02s\n","epoch 9  | loss: 0.68661 | valid_accuracy: 0.53573 |  0:01:09s\n","epoch 10 | loss: 0.68623 | valid_accuracy: 0.53866 |  0:01:16s\n","Stop training because you reached max_epochs = 11 with best_epoch = 10 and best_valid_accuracy = 0.53866\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:30:44,093] Trial 6 finished with value: 0.5386649122165771 and parameters: {'max_epochs': 11, 'batch_size': 1024, 'learning_rate': 0.058883681328691116}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69411 | valid_accuracy: 0.50628 |  0:00:11s\n","epoch 1  | loss: 0.6928  | valid_accuracy: 0.5134  |  0:00:24s\n","epoch 2  | loss: 0.69144 | valid_accuracy: 0.5221  |  0:00:35s\n","epoch 3  | loss: 0.69177 | valid_accuracy: 0.50072 |  0:00:47s\n","epoch 4  | loss: 0.69316 | valid_accuracy: 0.50071 |  0:00:59s\n","epoch 5  | loss: 0.69316 | valid_accuracy: 0.50071 |  0:01:11s\n","epoch 6  | loss: 0.69316 | valid_accuracy: 0.50071 |  0:01:23s\n","epoch 7  | loss: 0.69316 | valid_accuracy: 0.50071 |  0:01:35s\n","\n","Early stopping occurred at epoch 7 with best_epoch = 2 and best_valid_accuracy = 0.5221\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:32:44,411] Trial 7 finished with value: 0.5220951058152711 and parameters: {'max_epochs': 10, 'batch_size': 512, 'learning_rate': 0.08292480581796846}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69429 | valid_accuracy: 0.50083 |  0:00:22s\n","epoch 1  | loss: 0.69317 | valid_accuracy: 0.50071 |  0:00:44s\n","epoch 2  | loss: 0.69316 | valid_accuracy: 0.50071 |  0:01:07s\n","epoch 3  | loss: 0.69316 | valid_accuracy: 0.50071 |  0:01:29s\n","epoch 4  | loss: 0.69316 | valid_accuracy: 0.50071 |  0:01:52s\n","epoch 5  | loss: 0.69391 | valid_accuracy: 0.5007  |  0:02:15s\n","\n","Early stopping occurred at epoch 5 with best_epoch = 0 and best_valid_accuracy = 0.50083\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:35:46,738] Trial 8 finished with value: 0.500834582160654 and parameters: {'max_epochs': 20, 'batch_size': 256, 'learning_rate': 0.09390376228184368}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.73797 | valid_accuracy: 0.49798 |  0:00:07s\n","epoch 1  | loss: 0.69889 | valid_accuracy: 0.5064  |  0:00:13s\n","epoch 2  | loss: 0.69516 | valid_accuracy: 0.51532 |  0:00:20s\n","epoch 3  | loss: 0.69404 | valid_accuracy: 0.51831 |  0:00:27s\n","epoch 4  | loss: 0.69361 | valid_accuracy: 0.51911 |  0:00:34s\n","epoch 5  | loss: 0.69259 | valid_accuracy: 0.52097 |  0:00:41s\n","epoch 6  | loss: 0.69247 | valid_accuracy: 0.52123 |  0:00:48s\n","epoch 7  | loss: 0.69196 | valid_accuracy: 0.52435 |  0:00:55s\n","epoch 8  | loss: 0.6916  | valid_accuracy: 0.52359 |  0:01:02s\n","epoch 9  | loss: 0.69122 | valid_accuracy: 0.52346 |  0:01:09s\n","epoch 10 | loss: 0.69111 | valid_accuracy: 0.52401 |  0:01:16s\n","Stop training because you reached max_epochs = 11 with best_epoch = 7 and best_valid_accuracy = 0.52435\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:37:16,491] Trial 9 finished with value: 0.5243490868330958 and parameters: {'max_epochs': 11, 'batch_size': 1024, 'learning_rate': 0.0014501238871324294}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69615 | valid_accuracy: 0.52387 |  0:00:11s\n","epoch 1  | loss: 0.69164 | valid_accuracy: 0.51761 |  0:00:23s\n","epoch 2  | loss: 0.69075 | valid_accuracy: 0.51907 |  0:00:35s\n","epoch 3  | loss: 0.69024 | valid_accuracy: 0.52163 |  0:00:47s\n","epoch 4  | loss: 0.68965 | valid_accuracy: 0.52973 |  0:00:59s\n","epoch 5  | loss: 0.68939 | valid_accuracy: 0.531   |  0:01:11s\n","epoch 6  | loss: 0.68902 | valid_accuracy: 0.53014 |  0:01:23s\n","epoch 7  | loss: 0.68924 | valid_accuracy: 0.52807 |  0:01:35s\n","epoch 8  | loss: 0.68905 | valid_accuracy: 0.52337 |  0:01:47s\n","epoch 9  | loss: 0.68918 | valid_accuracy: 0.52716 |  0:01:59s\n","epoch 10 | loss: 0.68892 | valid_accuracy: 0.52892 |  0:02:11s\n","\n","Early stopping occurred at epoch 10 with best_epoch = 5 and best_valid_accuracy = 0.531\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:39:52,094] Trial 10 finished with value: 0.531001376755973 and parameters: {'max_epochs': 24, 'batch_size': 512, 'learning_rate': 0.022522534203202937}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69621 | valid_accuracy: 0.50189 |  0:00:06s\n","epoch 1  | loss: 0.69031 | valid_accuracy: 0.52149 |  0:00:13s\n","epoch 2  | loss: 0.68967 | valid_accuracy: 0.52045 |  0:00:20s\n","epoch 3  | loss: 0.68958 | valid_accuracy: 0.5264  |  0:00:27s\n","epoch 4  | loss: 0.68909 | valid_accuracy: 0.53062 |  0:00:34s\n","epoch 5  | loss: 0.68927 | valid_accuracy: 0.53157 |  0:00:41s\n","epoch 6  | loss: 0.6886  | valid_accuracy: 0.53084 |  0:00:48s\n","epoch 7  | loss: 0.68835 | valid_accuracy: 0.53302 |  0:00:55s\n","epoch 8  | loss: 0.68782 | valid_accuracy: 0.53282 |  0:01:02s\n","epoch 9  | loss: 0.68741 | valid_accuracy: 0.53367 |  0:01:09s\n","epoch 10 | loss: 0.68694 | valid_accuracy: 0.53339 |  0:01:16s\n","epoch 11 | loss: 0.68711 | valid_accuracy: 0.53748 |  0:01:23s\n","epoch 12 | loss: 0.68676 | valid_accuracy: 0.53803 |  0:01:30s\n","epoch 13 | loss: 0.68646 | valid_accuracy: 0.53669 |  0:01:37s\n","epoch 14 | loss: 0.68816 | valid_accuracy: 0.5246  |  0:01:44s\n","epoch 15 | loss: 0.68893 | valid_accuracy: 0.52787 |  0:01:51s\n","epoch 16 | loss: 0.68889 | valid_accuracy: 0.52744 |  0:01:58s\n","epoch 17 | loss: 0.68865 | valid_accuracy: 0.52725 |  0:02:05s\n","\n","Early stopping occurred at epoch 17 with best_epoch = 12 and best_valid_accuracy = 0.53803\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:42:10,495] Trial 11 finished with value: 0.5380313607953507 and parameters: {'max_epochs': 19, 'batch_size': 1024, 'learning_rate': 0.0338436026980793}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.69547 | valid_accuracy: 0.51139 |  0:00:06s\n","epoch 1  | loss: 0.69017 | valid_accuracy: 0.52309 |  0:00:13s\n","epoch 2  | loss: 0.68935 | valid_accuracy: 0.52623 |  0:00:20s\n","epoch 3  | loss: 0.68884 | valid_accuracy: 0.52231 |  0:00:27s\n","epoch 4  | loss: 0.68866 | valid_accuracy: 0.52817 |  0:00:34s\n","epoch 5  | loss: 0.68848 | valid_accuracy: 0.52752 |  0:00:41s\n","epoch 6  | loss: 0.6884  | valid_accuracy: 0.52759 |  0:00:48s\n","epoch 7  | loss: 0.6885  | valid_accuracy: 0.53377 |  0:00:55s\n","epoch 8  | loss: 0.68795 | valid_accuracy: 0.53205 |  0:01:02s\n","epoch 9  | loss: 0.68732 | valid_accuracy: 0.53496 |  0:01:08s\n","epoch 10 | loss: 0.68736 | valid_accuracy: 0.53374 |  0:01:15s\n","epoch 11 | loss: 0.68728 | valid_accuracy: 0.53676 |  0:01:22s\n","epoch 12 | loss: 0.68671 | valid_accuracy: 0.53405 |  0:01:29s\n","epoch 13 | loss: 0.68661 | valid_accuracy: 0.53644 |  0:01:36s\n","epoch 14 | loss: 0.68639 | valid_accuracy: 0.5339  |  0:01:43s\n","epoch 15 | loss: 0.68633 | valid_accuracy: 0.53418 |  0:01:50s\n","Stop training because you reached max_epochs = 16 with best_epoch = 11 and best_valid_accuracy = 0.53676\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:44:14,372] Trial 12 finished with value: 0.5367642579528978 and parameters: {'max_epochs': 16, 'batch_size': 1024, 'learning_rate': 0.034538087263499995}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.70087 | valid_accuracy: 0.51627 |  0:00:11s\n","epoch 1  | loss: 0.69166 | valid_accuracy: 0.52158 |  0:00:23s\n","epoch 2  | loss: 0.69076 | valid_accuracy: 0.52146 |  0:00:35s\n","epoch 3  | loss: 0.6905  | valid_accuracy: 0.52291 |  0:00:47s\n","epoch 4  | loss: 0.68955 | valid_accuracy: 0.5288  |  0:00:59s\n","epoch 5  | loss: 0.68881 | valid_accuracy: 0.52836 |  0:01:11s\n","epoch 6  | loss: 0.68852 | valid_accuracy: 0.53209 |  0:01:23s\n","epoch 7  | loss: 0.68824 | valid_accuracy: 0.53142 |  0:01:35s\n","epoch 8  | loss: 0.68795 | valid_accuracy: 0.53329 |  0:01:47s\n","epoch 9  | loss: 0.68772 | valid_accuracy: 0.53313 |  0:01:59s\n","epoch 10 | loss: 0.68754 | valid_accuracy: 0.52945 |  0:02:10s\n","epoch 11 | loss: 0.68759 | valid_accuracy: 0.53626 |  0:02:22s\n","epoch 12 | loss: 0.68729 | valid_accuracy: 0.53444 |  0:02:34s\n","epoch 13 | loss: 0.68668 | valid_accuracy: 0.53669 |  0:02:46s\n","epoch 14 | loss: 0.68654 | valid_accuracy: 0.53983 |  0:02:58s\n","epoch 15 | loss: 0.68648 | valid_accuracy: 0.54027 |  0:03:10s\n","epoch 16 | loss: 0.68599 | valid_accuracy: 0.54127 |  0:03:22s\n","epoch 17 | loss: 0.68554 | valid_accuracy: 0.53991 |  0:03:34s\n","epoch 18 | loss: 0.68554 | valid_accuracy: 0.54059 |  0:03:46s\n","epoch 19 | loss: 0.68474 | valid_accuracy: 0.54377 |  0:03:58s\n","epoch 20 | loss: 0.6844  | valid_accuracy: 0.54262 |  0:04:10s\n","epoch 21 | loss: 0.68415 | valid_accuracy: 0.5418  |  0:04:21s\n","epoch 22 | loss: 0.68358 | valid_accuracy: 0.54189 |  0:04:33s\n","epoch 23 | loss: 0.6835  | valid_accuracy: 0.53792 |  0:04:45s\n","Stop training because you reached max_epochs = 24 with best_epoch = 19 and best_valid_accuracy = 0.54377\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:49:24,780] Trial 13 finished with value: 0.5437698746299207 and parameters: {'max_epochs': 24, 'batch_size': 512, 'learning_rate': 0.010156722704117261}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.70135 | valid_accuracy: 0.51934 |  0:00:11s\n","epoch 1  | loss: 0.69141 | valid_accuracy: 0.52342 |  0:00:23s\n","epoch 2  | loss: 0.69032 | valid_accuracy: 0.52724 |  0:00:35s\n","epoch 3  | loss: 0.68949 | valid_accuracy: 0.52766 |  0:00:47s\n","epoch 4  | loss: 0.68869 | valid_accuracy: 0.52629 |  0:00:59s\n","epoch 5  | loss: 0.68861 | valid_accuracy: 0.52865 |  0:01:11s\n","epoch 6  | loss: 0.68845 | valid_accuracy: 0.52754 |  0:01:23s\n","epoch 7  | loss: 0.68878 | valid_accuracy: 0.52495 |  0:01:35s\n","epoch 8  | loss: 0.68884 | valid_accuracy: 0.52881 |  0:01:47s\n","epoch 9  | loss: 0.68833 | valid_accuracy: 0.52708 |  0:01:59s\n","epoch 10 | loss: 0.68808 | valid_accuracy: 0.53201 |  0:02:11s\n","epoch 11 | loss: 0.68772 | valid_accuracy: 0.53204 |  0:02:23s\n","epoch 12 | loss: 0.68766 | valid_accuracy: 0.52933 |  0:02:35s\n","epoch 13 | loss: 0.68791 | valid_accuracy: 0.53166 |  0:02:47s\n","epoch 14 | loss: 0.68774 | valid_accuracy: 0.53156 |  0:02:59s\n","epoch 15 | loss: 0.68761 | valid_accuracy: 0.53302 |  0:03:10s\n","epoch 16 | loss: 0.68738 | valid_accuracy: 0.53591 |  0:03:22s\n","epoch 17 | loss: 0.68785 | valid_accuracy: 0.52955 |  0:03:34s\n","epoch 18 | loss: 0.68769 | valid_accuracy: 0.53038 |  0:03:46s\n","epoch 19 | loss: 0.68692 | valid_accuracy: 0.53782 |  0:03:58s\n","epoch 20 | loss: 0.68667 | valid_accuracy: 0.53764 |  0:04:10s\n","epoch 21 | loss: 0.68635 | valid_accuracy: 0.53784 |  0:04:22s\n","epoch 22 | loss: 0.68649 | valid_accuracy: 0.53606 |  0:04:34s\n","epoch 23 | loss: 0.68674 | valid_accuracy: 0.53213 |  0:04:46s\n","Stop training because you reached max_epochs = 24 with best_epoch = 21 and best_valid_accuracy = 0.53784\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 18:54:35,837] Trial 14 finished with value: 0.5378364218965118 and parameters: {'max_epochs': 24, 'batch_size': 512, 'learning_rate': 0.008018073235956063}. Best is trial 2 with value: 0.5440744666593564.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.70141 | valid_accuracy: 0.5163  |  0:00:11s\n","epoch 1  | loss: 0.691   | valid_accuracy: 0.52556 |  0:00:23s\n","epoch 2  | loss: 0.68995 | valid_accuracy: 0.52849 |  0:00:35s\n","epoch 3  | loss: 0.68893 | valid_accuracy: 0.53015 |  0:00:47s\n","epoch 4  | loss: 0.68838 | valid_accuracy: 0.53172 |  0:00:59s\n","epoch 5  | loss: 0.68806 | valid_accuracy: 0.53081 |  0:01:11s\n","epoch 6  | loss: 0.68776 | valid_accuracy: 0.53337 |  0:01:23s\n","epoch 7  | loss: 0.68751 | valid_accuracy: 0.53508 |  0:01:35s\n","epoch 8  | loss: 0.68724 | valid_accuracy: 0.53416 |  0:01:46s\n","epoch 9  | loss: 0.68717 | valid_accuracy: 0.53753 |  0:01:58s\n","epoch 10 | loss: 0.68651 | valid_accuracy: 0.53668 |  0:02:10s\n","epoch 11 | loss: 0.68626 | valid_accuracy: 0.54061 |  0:02:22s\n","epoch 12 | loss: 0.68573 | valid_accuracy: 0.54041 |  0:02:34s\n","epoch 13 | loss: 0.68543 | valid_accuracy: 0.5373  |  0:02:46s\n","epoch 14 | loss: 0.68517 | valid_accuracy: 0.54167 |  0:02:58s\n","epoch 15 | loss: 0.68492 | valid_accuracy: 0.54057 |  0:03:10s\n","epoch 16 | loss: 0.68462 | valid_accuracy: 0.54361 |  0:03:21s\n","epoch 17 | loss: 0.6847  | valid_accuracy: 0.54423 |  0:03:33s\n","epoch 18 | loss: 0.68406 | valid_accuracy: 0.54236 |  0:03:45s\n","epoch 19 | loss: 0.6838  | valid_accuracy: 0.54622 |  0:03:57s\n","epoch 20 | loss: 0.68379 | valid_accuracy: 0.54471 |  0:04:09s\n","epoch 21 | loss: 0.68355 | valid_accuracy: 0.54415 |  0:04:21s\n","epoch 22 | loss: 0.68299 | valid_accuracy: 0.54504 |  0:04:33s\n","epoch 23 | loss: 0.68309 | valid_accuracy: 0.54684 |  0:04:45s\n","epoch 24 | loss: 0.68308 | valid_accuracy: 0.54551 |  0:04:57s\n","epoch 25 | loss: 0.68315 | valid_accuracy: 0.54261 |  0:05:08s\n","epoch 26 | loss: 0.68283 | valid_accuracy: 0.54744 |  0:05:20s\n","epoch 27 | loss: 0.68276 | valid_accuracy: 0.54796 |  0:05:32s\n","epoch 28 | loss: 0.68297 | valid_accuracy: 0.54771 |  0:05:44s\n","epoch 29 | loss: 0.68221 | valid_accuracy: 0.5471  |  0:05:56s\n","Stop training because you reached max_epochs = 30 with best_epoch = 27 and best_valid_accuracy = 0.54796\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 19:00:56,758] Trial 15 finished with value: 0.5479610609549569 and parameters: {'max_epochs': 30, 'batch_size': 512, 'learning_rate': 0.008836208769242107}. Best is trial 15 with value: 0.5479610609549569.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.70252 | valid_accuracy: 0.51286 |  0:00:11s\n","epoch 1  | loss: 0.69165 | valid_accuracy: 0.5234  |  0:00:23s\n","epoch 2  | loss: 0.69062 | valid_accuracy: 0.52588 |  0:00:35s\n","epoch 3  | loss: 0.69005 | valid_accuracy: 0.52721 |  0:00:47s\n","epoch 4  | loss: 0.68923 | valid_accuracy: 0.52698 |  0:00:59s\n","epoch 5  | loss: 0.68876 | valid_accuracy: 0.52999 |  0:01:11s\n","epoch 6  | loss: 0.68804 | valid_accuracy: 0.52961 |  0:01:23s\n","epoch 7  | loss: 0.68821 | valid_accuracy: 0.53033 |  0:01:35s\n","epoch 8  | loss: 0.6877  | valid_accuracy: 0.53345 |  0:01:46s\n","epoch 9  | loss: 0.68728 | valid_accuracy: 0.53438 |  0:01:58s\n","epoch 10 | loss: 0.68733 | valid_accuracy: 0.53492 |  0:02:10s\n","epoch 11 | loss: 0.68712 | valid_accuracy: 0.53073 |  0:02:22s\n","epoch 12 | loss: 0.6873  | valid_accuracy: 0.5311  |  0:02:34s\n","epoch 13 | loss: 0.68662 | valid_accuracy: 0.53385 |  0:02:46s\n","epoch 14 | loss: 0.68646 | valid_accuracy: 0.53644 |  0:02:58s\n","epoch 15 | loss: 0.68614 | valid_accuracy: 0.53461 |  0:03:10s\n","epoch 16 | loss: 0.68576 | valid_accuracy: 0.5343  |  0:03:22s\n","epoch 17 | loss: 0.68575 | valid_accuracy: 0.53481 |  0:03:34s\n","epoch 18 | loss: 0.68594 | valid_accuracy: 0.52939 |  0:03:46s\n","epoch 19 | loss: 0.68499 | valid_accuracy: 0.53173 |  0:03:57s\n","\n","Early stopping occurred at epoch 19 with best_epoch = 14 and best_valid_accuracy = 0.53644\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 19:05:19,127] Trial 16 finished with value: 0.5364352985611073 and parameters: {'max_epochs': 30, 'batch_size': 512, 'learning_rate': 0.006512395132047262}. Best is trial 15 with value: 0.5479610609549569.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.70467 | valid_accuracy: 0.50945 |  0:00:11s\n","epoch 1  | loss: 0.69171 | valid_accuracy: 0.52404 |  0:00:23s\n","epoch 2  | loss: 0.6905  | valid_accuracy: 0.52442 |  0:00:35s\n","epoch 3  | loss: 0.69011 | valid_accuracy: 0.52702 |  0:00:47s\n","epoch 4  | loss: 0.68947 | valid_accuracy: 0.5283  |  0:00:59s\n","epoch 5  | loss: 0.68878 | valid_accuracy: 0.52824 |  0:01:11s\n","epoch 6  | loss: 0.68819 | valid_accuracy: 0.53009 |  0:01:23s\n","epoch 7  | loss: 0.68775 | valid_accuracy: 0.534   |  0:01:35s\n","epoch 8  | loss: 0.68727 | valid_accuracy: 0.53478 |  0:01:47s\n","epoch 9  | loss: 0.68702 | valid_accuracy: 0.53631 |  0:01:59s\n","epoch 10 | loss: 0.68705 | valid_accuracy: 0.53668 |  0:02:11s\n","epoch 11 | loss: 0.6867  | valid_accuracy: 0.53901 |  0:02:23s\n","epoch 12 | loss: 0.68636 | valid_accuracy: 0.53882 |  0:02:34s\n","epoch 13 | loss: 0.68618 | valid_accuracy: 0.53715 |  0:02:46s\n","epoch 14 | loss: 0.68623 | valid_accuracy: 0.53765 |  0:02:58s\n","epoch 15 | loss: 0.68642 | valid_accuracy: 0.53835 |  0:03:10s\n","epoch 16 | loss: 0.68615 | valid_accuracy: 0.5388  |  0:03:22s\n","\n","Early stopping occurred at epoch 16 with best_epoch = 11 and best_valid_accuracy = 0.53901\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2023-10-29 19:09:06,644] Trial 17 finished with value: 0.5390060552895451 and parameters: {'max_epochs': 27, 'batch_size': 512, 'learning_rate': 0.005136343147708747}. Best is trial 15 with value: 0.5479610609549569.\n","\u003cipython-input-15-11ea38e9d19a\u003e:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]}],"source":["import optuna\n","from pytorch_tabnet.tab_model import TabNetClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Optuna를 위한 목적 함수 정의\n","def objective(trial):\n","\n","    # 탐색할 하이퍼파라미터 설정\n","    param = {\n","        'max_epochs': trial.suggest_int('max_epochs', 10, 30),\n","        'batch_size': trial.suggest_categorical('batch_size', [256, 512, 1024]),\n","        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","    }\n","\n","    # 모델 생성\n","    model = TabNetClassifier(optimizer_params=dict(lr=param['learning_rate']))\n","\n","    # 모델 학습\n","    model.fit(\n","        X_train, y_train,\n","        eval_set=[(X_valid, y_valid)],\n","        eval_name=['valid'],\n","        eval_metric=['accuracy'],\n","        max_epochs=param['max_epochs'],\n","        batch_size=param['batch_size'],\n","        patience=5,\n","        virtual_batch_size=128,\n","        num_workers=0,\n","        drop_last=False\n","    )\n","\n","    # 검증 데이터에 대한 예측 및 정확도 측정\n","    preds = model.predict(X_valid)\n","    acc = accuracy_score(y_valid, preds)\n","    return acc\n","\n","# Optuna study 객체 생성\n","study = optuna.create_study(direction='maximize', study_name='TabNet optimization')\n","\n","# 목적 함수에 대한 최적화 실행\n","study.optimize(objective, n_trials=20)  # n_trials는 시도할 횟수입니다.\n","\n","# 최적의 하이퍼파라미터 출력\n","print(f\"Best trial: {study.best_trial.params}\")\n","print(f\"Best validation accuracy: {study.best_trial.value}\")\n","\n","# 최적의 하이퍼파라미터를 사용하여 최종 모델 학습\n","best_params = study.best_trial.params\n","best_model = TabNetClassifier(optimizer_params=dict(lr=best_params['learning_rate']))\n","\n","best_model.fit(\n","    X_train, y_train,\n","    eval_set=[(X_valid, y_valid)],\n","    max_epochs=best_params['max_epochs'],\n","    batch_size=best_params['batch_size'],\n","    patience=10,\n","    virtual_batch_size=128,\n","    num_workers=0,\n","    drop_last=False\n",")\n","\n","# 테스트 데이터에 대한 최종 평가\n","final_preds = best_model.predict(X_test)\n","final_acc = accuracy_score(y_test, final_preds)\n","print(f\"Test accuracy: {final_acc}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2CbMBaIqOXFn"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOiokP8+XhkX266bv8HsHEb","machine_shape":"hm","mount_file_id":"1EoQn0Db3qoiiUGfPNFhylZoxI0ESn7-V","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}