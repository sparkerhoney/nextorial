{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5115,"status":"ok","timestamp":1698597401764,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"aBN38mPBuvUv","outputId":"f4938ec7-1d1e-4296-bbe8-fbfffc6b91d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n","Requirement already satisfied: scikit_learn\u003e0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n","Requirement already satisfied: scipy\u003e1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.3)\n","Requirement already satisfied: torch\u003e=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.1.0+cu118)\n","Requirement already satisfied: tqdm\u003e=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn\u003e0.21-\u003epytorch-tabnet) (1.3.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn\u003e0.21-\u003epytorch-tabnet) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3-\u003epytorch-tabnet) (2.1.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.3-\u003epytorch-tabnet) (2.1.3)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.3-\u003epytorch-tabnet) (1.3.0)\n","Installing collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-4.1.0\n"]}],"source":["! pip install pytorch-tabnet"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5302,"status":"ok","timestamp":1698597407062,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"IpKn2mzLOkJc","outputId":"5d5f995e-8f88-44c0-dcab-d760c6f037da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting optuna\n","  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic\u003e=1.5.0 (from optuna)\n","  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog (from optuna)\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n","Requirement already satisfied: sqlalchemy\u003e=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.22)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic\u003e=1.5.0-\u003eoptuna)\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions\u003e=4 in /usr/local/lib/python3.10/dist-packages (from alembic\u003e=1.5.0-\u003eoptuna) (4.5.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy\u003e=1.3.0-\u003eoptuna) (3.0.0)\n","Requirement already satisfied: MarkupSafe\u003e=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako-\u003ealembic\u003e=1.5.0-\u003eoptuna) (2.1.3)\n","Installing collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.12.1 colorlog-6.7.0 optuna-3.4.0\n"]}],"source":["! pip install optuna"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1641,"status":"ok","timestamp":1698597428013,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"SWrLKXATvQ3L"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2371,"status":"ok","timestamp":1698597431075,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"DJVHmzp3wXUl"},"outputs":[],"source":["match_data = pd.read_csv('/content/drive/MyDrive/nextorial/data/match_data.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/nextorial/data/test_data.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1698597431075,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"d9IDB-y-vpZc"},"outputs":[],"source":["class DataProcessor:\n","\n","    def __init__(self, df):\n","        self.data = df\n","\n","    @staticmethod\n","    # def convert_tier_to_numeric(tier):\n","    #     tier_dict = {\n","    #         'unranked': 0,\n","    #         'bronze': 1,\n","    #         'silver': 2,\n","    #         'gold': 3,\n","    #         'platinum': 4,\n","    #         'diamond': 5,\n","    #         'master': 6\n","    #     }\n","    #     return tier_dict.get(tier, -1)\n","\n","    @staticmethod\n","    def convert_tier_to_exponential_weight(tier):\n","        tier_dict = {\n","            'unranked': 0,\n","            'bronze': 1,\n","            'silver': 2,\n","            'gold': 3,\n","            'platinum': 4,\n","            'diamond': 5,\n","            'master': 6\n","        }\n","        tier_numeric = tier_dict.get(tier, -1)\n","        return np.exp(tier_numeric)\n","\n","    def add_tier_exponential_weight(self):\n","        self.data['tier_exp_weight'] = self.data['tier'].apply(self.convert_tier_to_exponential_weight)\n","        return self.data\n","\n","    # def calculate_team_features(self):\n","    #     return self.data.groupby(['matchid', 'teamid']).agg({\n","    #         'mmr': 'mean',\n","    #         'winstreak': 'mean',\n","    #         'losestreak': 'mean',\n","    #         'recentwinprob': 'mean'\n","    #     }).reset_index()\n","\n","    def preprocess(self):\n","        # match_team_features = self.calculate_team_features()\n","        # self.data = self.data.merge(match_team_features, on=['matchid', 'teamid'], suffixes=('', '_team_avg'))\n","        self.data = self.normalize_column('accumatches')\n","        self.data = self.compute_team_stats()\n","        self.data = self.compute_recent_performance_index()\n","        self.data = self.process_guild_info(202068.571428571428400)\n","        self.data = self.compute_mmr_diff_and_variance()\n","        self.data = self.compute_recent_winprob_stats()\n","        self.data = self.apply_tier_conversion_and_compute_average()\n","        self.data = self.compute_streak_rate()\n","        self.data = self.guild_mean()\n","        self.data = self.guild_median()\n","        self.data = self.guild_mode()\n","        self.data = self.add_tier_exponential_weight()\n","\n","    # guild_membership\n","    def guild_mean(self):\n","        df = self.data.copy()\n","        df['guildid'].fillna('NoGuild', inplace=True)\n","        df['tier_numeric'] = df['tier'].map(self.convert_tier_to_exponential_weight)\n","        guild_mean = df.groupby('guildid')[['mmr', 'winstreak', 'recentwinprob', 'accumatches', 'tier_numeric']].mean()\n","        new_columns = {col: f'{col}guild_mean' for col in guild_mean.columns}\n","        guild_mean.rename(columns=new_columns, inplace=True)\n","        df = pd.merge(df, guild_mean, on='guildid', how='left')\n","        return df\n","\n","    def guild_median(self):\n","        df = self.data.copy()\n","        df['guildid'].fillna('NoGuild', inplace=True)\n","        df['tier_numeric'] = df['tier'].map(self.convert_tier_to_exponential_weight)\n","        guild_median = df.groupby('guildid')[['mmr', 'winstreak', 'recentwinprob', 'accumatches', 'tier_numeric']].median()\n","        new_columns = {col: f'{col}guild_median' for col in guild_median.columns}\n","        guild_median.rename(columns=new_columns, inplace=True)\n","        df = pd.merge(df, guild_median, on='guildid', how='left')\n","        return df\n","\n","    def guild_mode(self):\n","        df = self.data.copy()\n","        df['guildid'].fillna('NoGuild', inplace=True)\n","        df['tier_numeric'] = df['tier'].map(self.convert_tier_to_exponential_weight)\n","\n","        def calculate_mode(group):\n","            return group.mode().iloc[0]\n","\n","        guild_mode = df.groupby('guildid')[['mmr', 'winstreak', 'recentwinprob', 'accumatches', 'tier_numeric']].apply(calculate_mode)\n","        new_columns = {col: f'{col}guild_mode' for col in guild_mode.columns}\n","        guild_mode.rename(columns=new_columns, inplace=True)\n","        df = pd.merge(df, guild_mode, on='guildid', how='left')\n","        return df\n","\n","    def normalize_column(self, column):\n","        self.data[f'normalized_{column}'] = (self.data[column] - self.data[column].min()) / (self.data[column].max() - self.data[column].min())\n","        return self.data\n","\n","    def compute_team_stats(self):\n","        grouped = self.data.groupby(['matchid', 'teamid'])\n","        self.data['team_max_accumatches'] = grouped['accumatches'].transform('max')\n","        self.data['team_min_accumatches'] = grouped['accumatches'].transform('min')\n","        self.data['accumatches_diff'] = self.data['team_max_accumatches'] - self.data['team_min_accumatches']\n","        self.data['accumatches_variance'] = grouped['accumatches'].transform('var')\n","        return self.data\n","\n","    def compute_recent_performance_index(self):\n","        self.data['recent_performance_index'] = self.data['winstreak'] * self.data['recentwinprob']\n","        return self.data\n","\n","    def process_guild_info(self, threshold):\n","        guild_mean_mmr = self.data.groupby('guildid')['mmr'].mean()\n","        self.data['guild_mean_mmr'] = self.data['guildid'].map(guild_mean_mmr)\n","        self.data['high_mmr_guild'] = (self.data['guild_mean_mmr'] \u003e threshold).astype(int)\n","        return self.data\n","\n","    def compute_mmr_diff_and_variance(self):\n","        mmr_diff_grouped = self.data.groupby('teamid')['mmr'].agg(['max', 'min'])\n","        self.data['mmr_diff'] = self.data['teamid'].map(mmr_diff_grouped['max'] - mmr_diff_grouped['min'])\n","        mmr_variance_grouped = self.data.groupby('teamid')['mmr'].var()\n","        self.data['mmr_variance'] = self.data['teamid'].map(mmr_variance_grouped)\n","        return self.data\n","\n","    def compute_recent_winprob_stats(self):\n","        grouped = self.data.groupby('matchid')\n","        self.data['recentwinprob_max'] = grouped['recentwinprob'].transform('max')\n","        self.data['recentwinprob_min'] = grouped['recentwinprob'].transform('min')\n","        self.data['recentwinprob_diff'] = self.data['recentwinprob_max'] - self.data['recentwinprob_min']\n","        self.data['recentwinprob_mean'] = grouped['recentwinprob'].transform('mean')\n","        self.data['recentwinprob_diff_from_mean'] = (self.data['recentwinprob'] - self.data['recentwinprob_mean'])**2\n","        self.data['recentwinprob_variance'] = grouped['recentwinprob_diff_from_mean'].transform('mean')\n","        return self.data\n","\n","    def apply_tier_conversion_and_compute_average(self):\n","        self.data['tier_numeric'] = self.data['tier'].apply(self.convert_tier_to_exponential_weight)\n","        average_tier = self.data.groupby(['matchid', 'teamid'])['tier_numeric'].mean().reset_index()\n","        average_tier.rename(columns={'tier_numeric': 'average_tier'}, inplace=True)\n","        self.data = self.data.merge(average_tier, on=['matchid', 'teamid'])\n","        return self.data\n","\n","    @staticmethod\n","    def calculate_streak_rate(row):\n","        winstreak, losestreak = row['winstreak'], row['losestreak']\n","        if winstreak + losestreak == 0:\n","            return 0\n","        return winstreak / (winstreak + losestreak)\n","\n","    def compute_streak_rate(self):\n","        self.data['streak_rate'] = self.data.apply(self.calculate_streak_rate, axis=1)\n","        return self.data"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":17264,"status":"ok","timestamp":1698597449186,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"Rtq23JFVwEt4"},"outputs":[],"source":["processor = DataProcessor(match_data)\n","processor.preprocess()\n","processed_data = processor.data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvSF3Jvv6Rbq"},"outputs":[],"source":["# # Processed data is already defined in the context, we'll just export it to a CSV file\n","# processed_data.to_csv('/content/drive/MyDrive/nextorial/data/processed_match_data.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Y_yZXSVm4_Gq"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split\n","\n","# 데이터에서 특성과 타겟 변수를 분리합니다.\n","target = 'matchresult'\n","# Drop identifiers and the original 'tier' feature\n","features_to_drop = ['createdatekst', 'matchid', 'accountid', 'guildid', 'tier', 'matchscore', 'isDrop', 'isEscape']\n","features = processed_data.columns.drop([target] + features_to_drop)\n","X = processed_data[features]\n","y = processed_data[target]\n","\n","# 수치형 및 범주형 데이터를 위한 변환기 정의\n","numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n","categorical_features = X.select_dtypes(include=['object']).columns\n","\n","# 순서형 특성은 이미 'tier_numeric'으로 변환되어 있으므로 여기서는 처리하지 않습니다.\n","\n","# 수치형 및 범주형 데이터에 대한 파이프라인을 만듭니다.\n","numeric_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median'))  # NaN 값을 중앙값으로 대체\n","])\n","\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),  # NaN 값을 최빈값으로 대체\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # 원-핫 인코딩\n","])\n","\n","# ColumnTransformer를 생성하여 변환기를 결합합니다.\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ],\n","    remainder='passthrough'  # 나머지 열은 변경하지 않고 유지\n",")\n","\n","# 전처리를 특성 데이터에 적용합니다.\n","X_encoded = preprocessor.fit_transform(X)\n","\n","# 데이터셋을 훈련 세트와 검증/테스트 세트로 분할합니다.\n","X_temp, X_test, y_temp, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zkjaWTV75tHN"},"outputs":[],"source":["import torch, gc\n","\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1908686,"status":"ok","timestamp":1698594373989,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"_5GHgZ9eQ7NR","outputId":"bc0b8bcb-9463-424e-eee1-ff1222cdbd6e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.68641 | val_0_auc: 0.58574 |  0:08:25s\n","epoch 1  | loss: 0.68401 | val_0_auc: 0.58654 |  0:17:22s\n","Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_val_0_auc = 0.58654\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}],"source":["# from pytorch_tabnet.tab_model import TabNetClassifier\n","\n","# clf = TabNetClassifier()\n","# clf.fit(\n","#     X_train, y_train,\n","#     eval_set=[(X_valid, y_valid)],\n","#     batch_size = 8,\n","#     max_epochs = 2,\n","# )\n","# preds = clf.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":622036,"status":"ok","timestamp":1698595972909,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"esRGsRfDJwZD","outputId":"f5d5cded-00e2-41c0-95e4-477b493834c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.68944 | val_0_auc: 0.57001 |  0:00:12s\n","epoch 1  | loss: 0.67928 | val_0_auc: 0.59253 |  0:00:24s\n","epoch 2  | loss: 0.678   | val_0_auc: 0.59655 |  0:00:36s\n","epoch 3  | loss: 0.67802 | val_0_auc: 0.59728 |  0:00:48s\n","epoch 4  | loss: 0.67714 | val_0_auc: 0.59968 |  0:01:00s\n","epoch 5  | loss: 0.67629 | val_0_auc: 0.60159 |  0:01:12s\n","epoch 6  | loss: 0.67559 | val_0_auc: 0.60327 |  0:01:24s\n","epoch 7  | loss: 0.67462 | val_0_auc: 0.60496 |  0:01:36s\n","epoch 8  | loss: 0.67441 | val_0_auc: 0.60629 |  0:01:48s\n","epoch 9  | loss: 0.67373 | val_0_auc: 0.60862 |  0:02:00s\n","epoch 10 | loss: 0.67488 | val_0_auc: 0.5941  |  0:02:13s\n","epoch 11 | loss: 0.6761  | val_0_auc: 0.60057 |  0:02:25s\n","epoch 12 | loss: 0.67553 | val_0_auc: 0.6047  |  0:02:37s\n","epoch 13 | loss: 0.67401 | val_0_auc: 0.60788 |  0:02:49s\n","epoch 14 | loss: 0.67305 | val_0_auc: 0.60875 |  0:03:01s\n","epoch 15 | loss: 0.67302 | val_0_auc: 0.60912 |  0:03:13s\n","epoch 16 | loss: 0.67268 | val_0_auc: 0.61012 |  0:03:26s\n","epoch 17 | loss: 0.67241 | val_0_auc: 0.61135 |  0:03:38s\n","epoch 18 | loss: 0.67196 | val_0_auc: 0.61219 |  0:03:50s\n","epoch 19 | loss: 0.67174 | val_0_auc: 0.61208 |  0:04:02s\n","epoch 20 | loss: 0.67182 | val_0_auc: 0.612   |  0:04:14s\n","epoch 21 | loss: 0.67192 | val_0_auc: 0.61251 |  0:04:26s\n","epoch 22 | loss: 0.67146 | val_0_auc: 0.61165 |  0:04:38s\n","epoch 23 | loss: 0.67111 | val_0_auc: 0.61255 |  0:04:50s\n","epoch 24 | loss: 0.671   | val_0_auc: 0.61186 |  0:05:02s\n","epoch 25 | loss: 0.67106 | val_0_auc: 0.61343 |  0:05:14s\n","epoch 26 | loss: 0.67074 | val_0_auc: 0.61477 |  0:05:26s\n","epoch 27 | loss: 0.67046 | val_0_auc: 0.61426 |  0:05:38s\n","epoch 28 | loss: 0.67062 | val_0_auc: 0.61396 |  0:05:50s\n","epoch 29 | loss: 0.6705  | val_0_auc: 0.61483 |  0:06:02s\n","epoch 30 | loss: 0.67013 | val_0_auc: 0.61609 |  0:06:14s\n","epoch 31 | loss: 0.66972 | val_0_auc: 0.61626 |  0:06:26s\n","epoch 32 | loss: 0.6699  | val_0_auc: 0.61667 |  0:06:38s\n","epoch 33 | loss: 0.67021 | val_0_auc: 0.61511 |  0:06:50s\n","epoch 34 | loss: 0.66971 | val_0_auc: 0.61666 |  0:07:02s\n","epoch 35 | loss: 0.66969 | val_0_auc: 0.61434 |  0:07:14s\n","epoch 36 | loss: 0.66943 | val_0_auc: 0.61845 |  0:07:26s\n","epoch 37 | loss: 0.66887 | val_0_auc: 0.61857 |  0:07:38s\n","epoch 38 | loss: 0.66933 | val_0_auc: 0.61479 |  0:07:50s\n","epoch 39 | loss: 0.66891 | val_0_auc: 0.61763 |  0:08:02s\n","epoch 40 | loss: 0.66898 | val_0_auc: 0.61706 |  0:08:14s\n","epoch 41 | loss: 0.66907 | val_0_auc: 0.61321 |  0:08:26s\n","epoch 42 | loss: 0.66989 | val_0_auc: 0.61628 |  0:08:38s\n","epoch 43 | loss: 0.66927 | val_0_auc: 0.61873 |  0:08:50s\n","epoch 44 | loss: 0.66954 | val_0_auc: 0.61616 |  0:09:02s\n","epoch 45 | loss: 0.66905 | val_0_auc: 0.6174  |  0:09:14s\n","epoch 46 | loss: 0.6687  | val_0_auc: 0.61875 |  0:09:26s\n","epoch 47 | loss: 0.66814 | val_0_auc: 0.61945 |  0:09:38s\n","epoch 48 | loss: 0.66805 | val_0_auc: 0.61865 |  0:09:50s\n","epoch 49 | loss: 0.66847 | val_0_auc: 0.62004 |  0:10:02s\n","Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_val_0_auc = 0.62004\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}],"source":["from pytorch_tabnet.tab_model import TabNetClassifier\n","\n","clf = TabNetClassifier()\n","clf.fit(\n","    X_train, y_train,\n","    eval_set=[(X_valid, y_valid)],\n","    batch_size = 4096,\n","    max_epochs = 50,\n",")\n","preds = clf.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CbMBaIqOXFn"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOkql8J3tAO7njkrgWuyZoJ","machine_shape":"hm","mount_file_id":"1iu1hASF-jdQF7_M1GDqR8EmrFXidJtV1","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}