{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6336,"status":"ok","timestamp":1698629878978,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"aBN38mPBuvUv","outputId":"8af52f54-1a45-4858-babe-1a356bcb8709"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.3)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n","Installing collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-4.1.0\n"]}],"source":["! pip install pytorch-tabnet"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4819,"status":"ok","timestamp":1698629883791,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"IpKn2mzLOkJc","outputId":"da98aadf-3641-4250-d06d-0a6f445ab5df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog (from optuna)\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.22)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n","Installing collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.12.1 colorlog-6.7.0 optuna-3.4.0\n"]}],"source":["! pip install optuna"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1717,"status":"ok","timestamp":1698629885501,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"SWrLKXATvQ3L"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2001,"status":"ok","timestamp":1698629887497,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"DJVHmzp3wXUl"},"outputs":[],"source":["match_data = pd.read_csv('/content/drive/MyDrive/nextorial/data/match_data.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/nextorial/data/test_data.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698629887497,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"d9IDB-y-vpZc"},"outputs":[],"source":["class DataProcessor:\n","\n","    def __init__(self, df):\n","        self.data = df\n","\n","    @staticmethod\n","    # def convert_tier_to_numeric(tier):\n","    #     tier_dict = {\n","    #         'unranked': 0,\n","    #         'bronze': 1,\n","    #         'silver': 2,\n","    #         'gold': 3,\n","    #         'platinum': 4,\n","    #         'diamond': 5,\n","    #         'master': 6\n","    #     }\n","    #     return tier_dict.get(tier, -1)\n","\n","    @staticmethod\n","    def convert_tier_to_exponential_weight(tier):\n","        tier_dict = {\n","            'unranked': 0,\n","            'bronze': 1,\n","            'silver': 2,\n","            'gold': 3,\n","            'platinum': 4,\n","            'diamond': 5,\n","            'master': 6\n","        }\n","        tier_numeric = tier_dict.get(tier, -1)\n","        return np.exp(tier_numeric)\n","\n","    def add_tier_exponential_weight(self):\n","        self.data['tier_exp_weight'] = self.data['tier'].apply(self.convert_tier_to_exponential_weight)\n","        return self.data\n","\n","    # def calculate_team_features(self):\n","    #     return self.data.groupby(['matchid', 'teamid']).agg({\n","    #         'mmr': 'mean',\n","    #         'winstreak': 'mean',\n","    #         'losestreak': 'mean',\n","    #         'recentwinprob': 'mean'\n","    #     }).reset_index()\n","\n","    def preprocess(self):\n","        # match_team_features = self.calculate_team_features()\n","        # self.data = self.data.merge(match_team_features, on=['matchid', 'teamid'], suffixes=('', '_team_avg'))\n","        self.data = self.normalize_column('accumatches')\n","        self.data = self.compute_team_stats()\n","        self.data = self.compute_recent_performance_index()\n","        self.data = self.process_guild_info(202068.571428571428400)\n","        self.data = self.compute_mmr_diff_and_variance()\n","        self.data = self.compute_recent_winprob_stats()\n","        self.data = self.apply_tier_conversion_and_compute_average()\n","        self.data = self.compute_streak_rate()\n","        self.data = self.guild_mean()\n","        self.data = self.guild_median()\n","        self.data = self.guild_mode()\n","        self.data = self.add_tier_exponential_weight()\n","\n","    # guild_membership\n","    def guild_mean(self):\n","        df = self.data.copy()\n","        df['guildid'].fillna('NoGuild', inplace=True)\n","        df['tier_numeric'] = df['tier'].map(self.convert_tier_to_exponential_weight)\n","        guild_mean = df.groupby('guildid')[['mmr', 'winstreak', 'recentwinprob', 'accumatches', 'tier_numeric']].mean()\n","        new_columns = {col: f'{col}guild_mean' for col in guild_mean.columns}\n","        guild_mean.rename(columns=new_columns, inplace=True)\n","        df = pd.merge(df, guild_mean, on='guildid', how='left')\n","        return df\n","\n","    def guild_median(self):\n","        df = self.data.copy()\n","        df['guildid'].fillna('NoGuild', inplace=True)\n","        df['tier_numeric'] = df['tier'].map(self.convert_tier_to_exponential_weight)\n","        guild_median = df.groupby('guildid')[['mmr', 'winstreak', 'recentwinprob', 'accumatches', 'tier_numeric']].median()\n","        new_columns = {col: f'{col}guild_median' for col in guild_median.columns}\n","        guild_median.rename(columns=new_columns, inplace=True)\n","        df = pd.merge(df, guild_median, on='guildid', how='left')\n","        return df\n","\n","    def guild_mode(self):\n","        df = self.data.copy()\n","        df['guildid'].fillna('NoGuild', inplace=True)\n","        df['tier_numeric'] = df['tier'].map(self.convert_tier_to_exponential_weight)\n","\n","        def calculate_mode(group):\n","            return group.mode().iloc[0]\n","\n","        guild_mode = df.groupby('guildid')[['mmr', 'winstreak', 'recentwinprob', 'accumatches', 'tier_numeric']].apply(calculate_mode)\n","        new_columns = {col: f'{col}guild_mode' for col in guild_mode.columns}\n","        guild_mode.rename(columns=new_columns, inplace=True)\n","        df = pd.merge(df, guild_mode, on='guildid', how='left')\n","        return df\n","\n","    def normalize_column(self, column):\n","        self.data[f'normalized_{column}'] = (self.data[column] - self.data[column].min()) / (self.data[column].max() - self.data[column].min())\n","        return self.data\n","\n","    def compute_team_stats(self):\n","        grouped = self.data.groupby(['matchid', 'teamid'])\n","        self.data['team_max_accumatches'] = grouped['accumatches'].transform('max')\n","        self.data['team_min_accumatches'] = grouped['accumatches'].transform('min')\n","        self.data['accumatches_diff'] = self.data['team_max_accumatches'] - self.data['team_min_accumatches']\n","        self.data['accumatches_variance'] = grouped['accumatches'].transform('var')\n","        return self.data\n","\n","    def compute_recent_performance_index(self):\n","        self.data['recent_performance_index'] = self.data['winstreak'] * self.data['recentwinprob']\n","        return self.data\n","\n","    def process_guild_info(self, threshold):\n","        guild_mean_mmr = self.data.groupby('guildid')['mmr'].mean()\n","        self.data['guild_mean_mmr'] = self.data['guildid'].map(guild_mean_mmr)\n","        self.data['high_mmr_guild'] = (self.data['guild_mean_mmr'] > threshold).astype(int)\n","        return self.data\n","\n","    def compute_mmr_diff_and_variance(self):\n","        mmr_diff_grouped = self.data.groupby('teamid')['mmr'].agg(['max', 'min'])\n","        self.data['mmr_diff'] = self.data['teamid'].map(mmr_diff_grouped['max'] - mmr_diff_grouped['min'])\n","        mmr_variance_grouped = self.data.groupby('teamid')['mmr'].var()\n","        self.data['mmr_variance'] = self.data['teamid'].map(mmr_variance_grouped)\n","        return self.data\n","\n","    def compute_recent_winprob_stats(self):\n","        grouped = self.data.groupby('matchid')\n","        self.data['recentwinprob_max'] = grouped['recentwinprob'].transform('max')\n","        self.data['recentwinprob_min'] = grouped['recentwinprob'].transform('min')\n","        self.data['recentwinprob_diff'] = self.data['recentwinprob_max'] - self.data['recentwinprob_min']\n","        self.data['recentwinprob_mean'] = grouped['recentwinprob'].transform('mean')\n","        self.data['recentwinprob_diff_from_mean'] = (self.data['recentwinprob'] - self.data['recentwinprob_mean'])**2\n","        self.data['recentwinprob_variance'] = grouped['recentwinprob_diff_from_mean'].transform('mean')\n","        return self.data\n","\n","    def apply_tier_conversion_and_compute_average(self):\n","        self.data['tier_numeric'] = self.data['tier'].apply(self.convert_tier_to_exponential_weight)\n","        average_tier = self.data.groupby(['matchid', 'teamid'])['tier_numeric'].mean().reset_index()\n","        average_tier.rename(columns={'tier_numeric': 'average_tier'}, inplace=True)\n","        self.data = self.data.merge(average_tier, on=['matchid', 'teamid'])\n","        return self.data\n","\n","    @staticmethod\n","    def calculate_streak_rate(row):\n","        winstreak, losestreak = row['winstreak'], row['losestreak']\n","        if winstreak + losestreak == 0:\n","            return 0\n","        return winstreak / (winstreak + losestreak)\n","\n","    def compute_streak_rate(self):\n","        self.data['streak_rate'] = self.data.apply(self.calculate_streak_rate, axis=1)\n","        return self.data"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":18734,"status":"ok","timestamp":1698629906223,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"Rtq23JFVwEt4"},"outputs":[],"source":["processor = DataProcessor(match_data)\n","processor.preprocess()\n","processed_data = processor.data"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698629906223,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"wvSF3Jvv6Rbq"},"outputs":[],"source":["# # Processed data is already defined in the context, we'll just export it to a CSV file\n","# processed_data.to_csv('/content/drive/MyDrive/nextorial/data/processed_match_data.csv', index=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5021,"status":"ok","timestamp":1698629911235,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"Y_yZXSVm4_Gq"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split\n","\n","# 데이터에서 특성과 타겟 변수를 분리합니다.\n","target = 'matchresult'\n","# Drop identifiers and the original 'tier' feature\n","features_to_drop = ['matchscore', 'isDrop', 'isEscape']\n","features = processed_data.columns.drop([target] + features_to_drop)\n","X = processed_data[features]\n","y = processed_data[target]\n","\n","# 수치형 및 범주형 데이터를 위한 변환기 정의\n","numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n","categorical_features = X.select_dtypes(include=['object']).columns\n","\n","# 순서형 특성은 이미 'tier_numeric'으로 변환되어 있으므로 여기서는 처리하지 않습니다.\n","\n","# 수치형 및 범주형 데이터에 대한 파이프라인을 만듭니다.\n","numeric_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median'))  # NaN 값을 중앙값으로 대체\n","])\n","\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),  # NaN 값을 최빈값으로 대체\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # 원-핫 인코딩\n","])\n","\n","# ColumnTransformer를 생성하여 변환기를 결합합니다.\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ],\n","    remainder='passthrough'  # 나머지 열은 변경하지 않고 유지\n",")\n","\n","# 전처리를 특성 데이터에 적용합니다.\n","X_encoded = preprocessor.fit_transform(X)\n","\n","# 데이터셋을 훈련 세트와 검증/테스트 세트로 분할합니다.\n","X_temp, X_test, y_temp, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3601,"status":"ok","timestamp":1698629914829,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"zkjaWTV75tHN"},"outputs":[],"source":["import torch, gc\n","\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1698629914829,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"_5GHgZ9eQ7NR"},"outputs":[],"source":["# from pytorch_tabnet.tab_model import TabNetClassifier\n","\n","# clf = TabNetClassifier()\n","# clf.fit(\n","#     X_train, y_train,\n","#     eval_set=[(X_valid, y_valid)],\n","#     batch_size = 8,\n","#     max_epochs = 2,\n","# )\n","# preds = clf.predict(X_test)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":527},"id":"esRGsRfDJwZD","executionInfo":{"status":"error","timestamp":1698629921046,"user_tz":-540,"elapsed":6228,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"}},"outputId":"641fee04-d906-44e6-d846-6b734d29ed2c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-441da28da086>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabNetClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m clf.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"network\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;31m# model has never been fitted before of warm_start is False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_network_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36m_set_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mmask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0mgroup_attention_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         ).to(self.device)\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 40.99 GiB. GPU 0 has a total capacty of 15.77 GiB of which 15.47 GiB is free. Process 26012 has 306.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["from pytorch_tabnet.tab_model import TabNetClassifier\n","\n","clf = TabNetClassifier()\n","clf.fit(\n","    X_train, y_train,\n","    eval_set=[(X_valid, y_valid)],\n","    batch_size = 1024,\n","    max_epochs = 10,\n",")\n","preds = clf.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1698629921048,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"Ao3oWNvbKkRE"},"outputs":[],"source":["# import optuna\n","# from pytorch_tabnet.tab_model import TabNetClassifier\n","# from sklearn.metrics import accuracy_score\n","\n","# # Optuna를 위한 목적 함수 정의\n","# def objective(trial):\n","\n","#     # 탐색할 하이퍼파라미터 설정\n","#     param = {\n","#         'max_epochs': trial.suggest_int('max_epochs', 10, 30),\n","#         'batch_size': trial.suggest_categorical('batch_size', [256, 512, 1024]),\n","#         'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n","#     }\n","\n","#     # 모델 생성\n","#     model = TabNetClassifier(optimizer_params=dict(lr=param['learning_rate']))\n","\n","#     # 모델 학습\n","#     model.fit(\n","#         X_train, y_train,\n","#         eval_set=[(X_valid, y_valid)],\n","#         eval_name=['valid'],\n","#         eval_metric=['accuracy'],\n","#         max_epochs=param['max_epochs'],\n","#         batch_size=param['batch_size'],\n","#         patience=5,\n","#         virtual_batch_size=128,\n","#         num_workers=0,\n","#         drop_last=False\n","#     )\n","\n","#     # 검증 데이터에 대한 예측 및 정확도 측정\n","#     preds = model.predict(X_valid)\n","#     acc = accuracy_score(y_valid, preds)\n","#     return acc\n","\n","# # Optuna study 객체 생성\n","# study = optuna.create_study(direction='maximize', study_name='TabNet optimization')\n","\n","# # 목적 함수에 대한 최적화 실행\n","# study.optimize(objective, n_trials=20)  # n_trials는 시도할 횟수입니다.\n","\n","# # 최적의 하이퍼파라미터 출력\n","# print(f\"Best trial: {study.best_trial.params}\")\n","# print(f\"Best validation accuracy: {study.best_trial.value}\")\n","\n","# # 최적의 하이퍼파라미터를 사용하여 최종 모델 학습\n","# best_params = study.best_trial.params\n","# best_model = TabNetClassifier(optimizer_params=dict(lr=best_params['learning_rate']))\n","\n","# best_model.fit(\n","#     X_train, y_train,\n","#     eval_set=[(X_valid, y_valid)],\n","#     max_epochs=best_params['max_epochs'],\n","#     batch_size=best_params['batch_size'],\n","#     patience=10,\n","#     virtual_batch_size=128,\n","#     num_workers=0,\n","#     drop_last=False\n","# )\n","\n","# # 테스트 데이터에 대한 최종 평가\n","# final_preds = best_model.predict(X_test)\n","# final_acc = accuracy_score(y_test, final_preds)\n","# print(f\"Test accuracy: {final_acc}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1698629921048,"user":{"displayName":"Honey Jeong","userId":"03929989360297315294"},"user_tz":-540},"id":"2CbMBaIqOXFn"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100","mount_file_id":"1iSUTqskuTUIb-HD4lem4cN9ELlaLe1pp","authorship_tag":"ABX9TyMWF48AwCLlla+1+5FUR5B0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}